{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5542d63-5fb0-4813-a070-d895655a1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading dependent packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23617d91-c159-4f79-b741-81f3da9ffa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the data directory\n",
    "data_dir: str = '../data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9ca8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializing the list to store the concatenatd data frames\n",
    "merged_df_list: list[pd.DataFrame] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00937837-6aca-4b71-bf57-afbfeb3cfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## locating all files that match the pattern input_2023_w[01-18].csv\n",
    "input_files: list[str] = sorted(glob.glob(os.path.join(data_dir, 'input_2023_w*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d72e2-09cc-4215-bd2a-a5e32fc7a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train\\output_2023_w01.csv\n"
     ]
    }
   ],
   "source": [
    "## locating all files that match the pattern output_2023_w[01-18].csv\n",
    "output_files = sorted(glob.glob(os.path.join(data_dir, 'output_2023_w*.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f957712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the keys to join the corresponding input files on the output files\n",
    "join_keys: list[str] = ['game_id', 'play_id', 'nfl_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95423cbd-ff59-44a5-84f4-b407cf74fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking if the lists have the same length before zipping\n",
    "if (len(input_files) != len(output_files)):\n",
    "    print('Warning: The number of input files does not match the number of output files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaca2765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'play_id', 'player_to_predict', 'nfl_id', 'frame_id',\n",
      "       'play_direction', 'absolute_yardline_number', 'player_name',\n",
      "       'player_height', 'player_weight', 'player_birth_date',\n",
      "       'player_position', 'player_side', 'player_role', 'x', 'y', 's', 'a',\n",
      "       'dir', 'o', 'num_frames_output', 'ball_land_x', 'ball_land_y'],\n",
      "      dtype='object')\n",
      "Index(['game_id', 'play_id', 'nfl_id', 'frame_id', 'x', 'y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Test W01 files\n",
    "w01_input = pd.read_csv('../data/train/input_2023_w01.csv')\n",
    "print(w01_input.columns)\n",
    "w01_output = pd.read_csv('../data/train/output_2023_w01.csv')\n",
    "print(w01_output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ada062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing w01: Loading input_2023_w01.csv and output_2023_w01.csv\n",
      "Processing w02: Loading input_2023_w02.csv and output_2023_w02.csv\n",
      "Processing w03: Loading input_2023_w03.csv and output_2023_w03.csv\n",
      "Processing w04: Loading input_2023_w04.csv and output_2023_w04.csv\n",
      "Processing w05: Loading input_2023_w05.csv and output_2023_w05.csv\n",
      "Processing w06: Loading input_2023_w06.csv and output_2023_w06.csv\n",
      "Processing w07: Loading input_2023_w07.csv and output_2023_w07.csv\n",
      "Processing w08: Loading input_2023_w08.csv and output_2023_w08.csv\n",
      "Processing w09: Loading input_2023_w09.csv and output_2023_w09.csv\n",
      "Processing w10: Loading input_2023_w10.csv and output_2023_w10.csv\n",
      "Processing w11: Loading input_2023_w11.csv and output_2023_w11.csv\n",
      "Processing w12: Loading input_2023_w12.csv and output_2023_w12.csv\n",
      "Processing w13: Loading input_2023_w13.csv and output_2023_w13.csv\n",
      "Processing w14: Loading input_2023_w14.csv and output_2023_w14.csv\n",
      "Processing w15: Loading input_2023_w15.csv and output_2023_w15.csv\n",
      "Processing w16: Loading input_2023_w16.csv and output_2023_w16.csv\n",
      "Processing w17: Loading input_2023_w17.csv and output_2023_w17.csv\n",
      "Processing w18: Loading input_2023_w18.csv and output_2023_w18.csv\n",
      "\n",
      "--- Final Summary ---\n",
      "Processing complete. Total 72 merged dataframes stored in \"merged_df_list.\"\n"
     ]
    }
   ],
   "source": [
    "## using zip to iterate over the corresponding input and output files simultaneously\n",
    "for input_file_path, output_file_path in zip(input_files, output_files):\n",
    "    \n",
    "    ## extracting the week identifier for clear matching\n",
    "    match = re.search(r'(w\\d{2})', os.path.basename(input_file_path))\n",
    "    week = match.group(0) if match else 'Unknown_Week'\n",
    "    # print(week)\n",
    "\n",
    "    try:\n",
    "        ## loading the dataframes\n",
    "        print(f'Processing {week}: Loading {os.path.basename(input_file_path)} and {os.path.basename(output_file_path)}')\n",
    "        input_df: pd.DataFrame = pd.read_csv(input_file_path, engine = 'python')\n",
    "        output_df: pd.DataFrame = pd.read_csv(output_file_path, engine = 'python')\n",
    "        # print(input_df.columns)\n",
    "        # print(output_df.columns)\n",
    "\n",
    "        ## renaming the overlapping target columns in the output file dataframe\n",
    "        output_df = output_df.rename(columns = {'x': 'target_x',\n",
    "                                                'y': 'target_y',\n",
    "                                                'frame_id': 'target_frame_id'})\n",
    "        # print(output_df.columns)\n",
    "\n",
    "        ## merging the input and output dataframes on the specified keys through an inner merge to keep rows that exist in both\n",
    "        ## the input and output files \n",
    "        merged_df: pd.DataFrame = pd.merge(\n",
    "            input_df,\n",
    "            output_df,\n",
    "            on = join_keys,\n",
    "            how = 'inner',\n",
    "            suffixes = ('_input', '_output')\n",
    "        )\n",
    "        # print(f'Printing week {week} merged df')\n",
    "        # print(merged_df.columns)\n",
    "\n",
    "        ## adding the merged dataframe to the dataframe list\n",
    "        merged_df_list.append(merged_df)\n",
    "\n",
    "        ## verifying that all columns are present in the merged dataframe\n",
    "        required_cols: list[str] = list(input_df.columns) + list(output_df.columns)\n",
    "        missing_cols: list[str] = [col for col in required_cols if col not in merged_df.columns]\n",
    "\n",
    "        if missing_cols:\n",
    "            print(f'Warning: merged dataframe for {week} is missing expected columns: {missing_cols}')\n",
    "            print(f'Successfully merged {week}, resulting in {len(merged_df)} rows')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(F'Error: File not found for {week}. Skipping.')\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f'Error: One of the files for {week} is empty. Skipping.')\n",
    "    except Exception as e:\n",
    "        print(f'An unexpected error occurred during processing {week}: {e}')\n",
    "\n",
    "print('\\n--- Final Summary ---')\n",
    "print(f'Processing complete. Total {len(merged_df_list)} merged dataframes stored in \"merged_df_list.\"')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl_bdb_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
